# üé§ Guia de Apresenta√ß√£o do Projeto

## Roteiro para Demonstra√ß√£o (15-20 minutos)

### 1. Introdu√ß√£o (2 min)

**Abertura:**
```
"Bom dia/tarde! Apresento o Pipeline de Dados de Mobilidade Urbana de 
Belo Horizonte, uma solu√ß√£o completa de engenharia de dados que extrai,
processa e analisa dados p√∫blicos de transporte coletivo."
```

**Pontos-chave:**
- ‚úÖ Dados p√∫blicos do Portal de Dados Abertos de BH
- ‚úÖ Arquitetura Medallion (Bronze-Silver-Gold)
- ‚úÖ Boas pr√°ticas de DataOps e governan√ßa
- ‚úÖ C√≥digo modular, testado e documentado

---

### 2. Demonstra√ß√£o da Arquitetura (3 min)

**Mostrar:** README.md - Se√ß√£o de Arquitetura

**Explicar:**
```
"A solu√ß√£o implementa a arquitetura Medallion em tr√™s camadas:

ü•â BRONZE: Dados brutos em Parquet
   - API Tempo Real de √¥nibus
   - MCO (Mapa de Controle Operacional)
   - Imut√°vel, append-only
   
ü•à SILVER: Dados limpos em Delta Lake
   - Valida√ß√µes de qualidade (Pandera)
   - Enriquecimento com features
   - ACID transactions
   
ü•á GOLD: M√©tricas de neg√≥cio
   - 4 m√©tricas principais agregadas
   - Otimizado para an√°lise
   - Pronto para BI tools"
```

**Destacar:**
- Por que Parquet? ‚Üí Efici√™ncia
- Por que Delta Lake? ‚Üí ACID + Time Travel
- Por que tr√™s camadas? ‚Üí Separa√ß√£o de concerns

---

### 3. Demonstra√ß√£o do C√≥digo (5 min)

#### 3.1 Estrutura do Projeto

**Mostrar:** Estrutura de diret√≥rios

```bash
tree /F /A
```

**Explicar:**
```
"C√≥digo organizado em pacotes:
- src/bronze: Ingest√£o
- src/silver: Transforma√ß√£o  
- src/gold: Agrega√ß√£o
- src/utils: Fun√ß√µes compartilhadas
- tests/: Testes unit√°rios"
```

#### 3.2 Exemplo de C√≥digo - Bronze Layer

**Abrir:** `src/bronze/ingestion.py`

**Destacar:**
```python
class OnibusTempoRealIngester(BronzeDataIngester):
    """Ingestor de dados de √¥nibus em tempo real."""
    
    def extract(self) -> pd.DataFrame:
        """Extrai dados de posicionamento."""
        # Implementa√ß√£o com retry e tratamento de erros
```

**Pontos:**
- Heran√ßa e reutiliza√ß√£o
- Docstrings completos
- Type hints
- Error handling

#### 3.3 Exemplo de C√≥digo - Silver Layer

**Abrir:** `src/silver/transformation.py`

**Destacar:**
```python
# Valida√ß√£o com Pandera
df = self.validator.validate_onibus_data(df)

# C√°lculo de quality score
df["_quality_score"] = self._calculate_quality_score(df)
```

**Pontos:**
- Valida√ß√µes autom√°ticas
- Score de qualidade
- Delta Lake

#### 3.4 Exemplo de C√≥digo - Gold Layer

**Abrir:** `src/gold/aggregation.py`

**Destacar:**
```python
class VelocidadeMediaPorLinhaAggregator(GoldAggregator):
    """Agrega velocidade m√©dia por linha."""
    
    def aggregate(self) -> pd.DataFrame:
        # Agrega√ß√µes SQL-like com Pandas
```

**Pontos:**
- M√©tricas de neg√≥cio
- Agrega√ß√µes eficientes
- Pronto para consumo

---

### 4. DataOps e Governan√ßa (3 min)

**Abrir:** `src/utils/data_quality.py`

**Demonstrar:**

```python
# Schema de valida√ß√£o
schema = DataFrameSchema({
    "latitude": Column(float, 
        checks=[Check.in_range(-20.0, -19.7)]),
    "velocidade": Column(float,
        checks=[Check.greater_than_or_equal_to(0)])
})
```

**Destacar:**
- ‚úÖ Valida√ß√µes autom√°ticas
- ‚úÖ Linhagem de dados rastre√°vel
- ‚úÖ Logs estruturados
- ‚úÖ M√©tricas de qualidade

**Mostrar:** Exemplo de log

```
2026-01-30 10:00:00 - INFO - Extraindo dados de: API
2026-01-30 10:00:02 - INFO - Extra√≠dos 1000 registros
2026-01-30 10:00:05 - INFO - Valida√ß√£o bem-sucedida: 1000 registros
```

---

### 5. Execu√ß√£o do Pipeline (3 min)

**Terminal:**

```bash
# Mostrar ajuda
python src/pipeline.py --help

# Executar exemplo
python exemplo_uso.py
```

**Op√ß√£o:** Se houver dados dispon√≠veis, executar pipeline real

```bash
python src/pipeline.py --layers bronze
```

**Explicar output:**
```
============================================================
INICIANDO CAMADA BRONZE - INGEST√ÉO DE DADOS
============================================================
Extraindo dados de: https://temporeal.pbh.gov.br/v1/posicoes
Extra√≠dos 850 registros
Dados salvos em: data/bronze/onibus_tempo_real/...
‚úì Camada Bronze conclu√≠da com sucesso
```

---

### 6. An√°lise com Notebooks (2 min)

**Abrir:** `notebooks/01_exploracao_dados.ipynb`

**Mostrar:**
- Carregamento de dados
- Estat√≠sticas descritivas
- Visualiza√ß√µes (gr√°ficos)

**Abrir:** `notebooks/02_analise_metricas.ipynb`

**Mostrar:**
- M√©tricas de neg√≥cio
- Dashboard de KPIs
- Insights

**Destacar:**
```
"Os notebooks permitem:
- Explora√ß√£o interativa
- Visualiza√ß√µes
- An√°lises ad-hoc
- Prototipagem de novas m√©tricas"
```

---

### 7. Testes e Qualidade (1 min)

**Terminal:**

```bash
# Executar testes
pytest -v

# Cobertura
pytest --cov=src --cov-report=term-missing
```

**Mostrar:** Output dos testes passando

**Explicar:**
```
"Testes garantem:
- C√≥digo funcional
- Regress√µes detectadas
- Refactoring seguro
- Documenta√ß√£o execut√°vel"
```

---

### 8. Documenta√ß√£o (1 min)

**Mostrar rapidamente:**
- README.md completo
- docs/ARCHITECTURE.md
- docs/OVERVIEW.md
- Docstrings no c√≥digo

**Destacar:**
```
"Documenta√ß√£o em m√∫ltiplos n√≠veis:
- README: Getting started
- Docs: Arquitetura detalhada
- C√≥digo: Docstrings completos
- Notebooks: Exemplos pr√°ticos"
```

---

### 9. Conclus√£o (1 min)

**Resumir:**

```
"Em resumo, este projeto entrega:

‚úÖ Pipeline ETL completo e funcional
‚úÖ Arquitetura Medallion implementada
‚úÖ 4 m√©tricas de neg√≥cio calculadas
‚úÖ DataOps: qualidade, governan√ßa, testes
‚úÖ C√≥digo limpo, modular e documentado
‚úÖ Pronto para produ√ß√£o e extens√≠vel

Pr√≥ximos passos sugeridos:
‚Üí Integra√ß√£o com Airflow
‚Üí Dashboard interativo
‚Üí Deploy em cloud
‚Üí Machine Learning"
```

**Perguntas:**
```
"Estou √† disposi√ß√£o para perguntas! üôã"
```

---

## üìã Checklist de Prepara√ß√£o

### Antes da Apresenta√ß√£o

- [ ] Testar pipeline localmente
- [ ] Verificar que todos os arquivos existem
- [ ] Preparar dados de exemplo (se necess√°rio)
- [ ] Testar notebooks (executar todas as c√©lulas)
- [ ] Verificar que testes passam
- [ ] Revisar README e documenta√ß√£o
- [ ] Preparar terminal com comandos prontos
- [ ] Ter editor de c√≥digo aberto (VS Code)
- [ ] Ter navegador pronto para mostrar APIs

### Durante a Apresenta√ß√£o

- [ ] Mostrar estrutura de diret√≥rios
- [ ] Demonstrar c√≥digo de cada camada
- [ ] Executar pipeline (ou exemplo)
- [ ] Mostrar notebooks com an√°lises
- [ ] Demonstrar testes passando
- [ ] Destacar pontos de DataOps
- [ ] Mencionar documenta√ß√£o
- [ ] Responder perguntas

---

## üéØ Pontos Fortes a Destacar

### 1. Arquitetura S√≥lida
- "Implementei a arquitetura Medallion, padr√£o de mercado para data lakes"
- "Separa√ß√£o clara entre dados brutos, limpos e agregados"

### 2. Qualidade de C√≥digo
- "C√≥digo seguindo PEP 8, com Black e Flake8"
- "Type hints e docstrings em todas as fun√ß√µes"
- "Modular e facilmente extens√≠vel"

### 3. DataOps (Diferencial!)
- "Valida√ß√µes autom√°ticas de qualidade com Pandera"
- "Linhagem de dados rastre√°vel"
- "Score de qualidade calculado para cada registro"
- "Logs estruturados e monitoramento"

### 4. Testabilidade
- "Testes unit√°rios com pytest"
- "Mocks para APIs externas"
- "Cobertura de c√≥digo implementada"

### 5. Documenta√ß√£o
- "README completo com exemplos"
- "Documenta√ß√£o t√©cnica detalhada"
- "Notebooks para explora√ß√£o"
- "Guias de instala√ß√£o e contribui√ß√£o"

### 6. Produ√ß√£o-Ready
- "Tratamento robusto de erros"
- "Retry mechanism implementado"
- "Configura√ß√µes externaliz√°veis"
- "Scripts de deploy (Windows/Linux)"

---

## üí° Respostas para Perguntas Comuns

### "Por que n√£o usou PySpark?"

```
"Optei por Pandas por alguns motivos:
1. Dados de BH cabem em mem√≥ria (milhares de registros)
2. Mais acess√≠vel para manuten√ß√£o
3. Mais r√°pido para desenvolvimento
4. C√≥digo est√° preparado para migra√ß√£o (estrutura modular)"
```

### "Como garantir qualidade dos dados?"

```
"Implementei m√∫ltiplas camadas de qualidade:
1. Valida√ß√µes com Pandera (schemas)
2. Regras de neg√≥cio (coordenadas, velocidade)
3. Score de qualidade calculado
4. Logs e monitoramento
5. Testes automatizados"
```

### "E se a API cair?"

```
"Implementei tratamento robusto:
1. Retry autom√°tico com backoff
2. Timeout configur√°vel
3. Logs detalhados de erros
4. Pipeline continua com outras fontes
5. Dados hist√≥ricos preservados"
```

### "Como escalar para mais dados?"

```
"Arquitetura preparada para escala:
1. Particionamento por data
2. Delta Lake suporta big data
3. C√≥digo modular facilita migra√ß√£o para PySpark
4. Cloud-ready (S3, Azure, GCP)
5. Chunk processing implementado"
```

### "Como adicionar novas fontes?"

```
"Processo simples:
1. Criar novo ingestor em src/bronze/
2. Seguir padr√£o da classe base
3. Adicionar config em config.yaml
4. Implementar testes
5. Documentar"
```

---

## üìä M√©tricas para Mencionar

- **30+ arquivos** organizados
- **3.000+ linhas** de c√≥digo
- **15+ m√≥dulos** Python
- **20+ testes** unit√°rios
- **4 m√©tricas** de neg√≥cio
- **3 camadas** (Medallion)
- **100%** seguindo PEP 8
- **80%+** cobertura de testes

---

## üé¨ Scripts Prontos para Copy-Paste

### Terminal 1: Estrutura
```bash
cd "Case BeAnalytic"
tree /F /A src
```

### Terminal 2: Execu√ß√£o
```bash
python exemplo_uso.py
```

### Terminal 3: Testes
```bash
pytest -v --cov=src
```

### VS Code: Arquivos para Abrir
1. README.md
2. src/pipeline.py
3. src/bronze/ingestion.py
4. src/silver/transformation.py
5. src/gold/aggregation.py
6. notebooks/01_exploracao_dados.ipynb

---

## ‚úÖ Resultado Esperado

Ap√≥s a apresenta√ß√£o, o avaliador deve entender:

1. ‚úÖ **Arquitetura**: Bronze-Silver-Gold implementada
2. ‚úÖ **C√≥digo**: Limpo, modular e bem documentado
3. ‚úÖ **Qualidade**: DataOps e governan√ßa presentes
4. ‚úÖ **Testes**: C√≥digo test√°vel e testado
5. ‚úÖ **Produ√ß√£o**: Pronto para deploy e extens√£o

---

**Boa sorte na apresenta√ß√£o! üöÄ**
